---
title: "Data Prep"
output: html_notebook
---


# Cleaning and exploring Play Therapy Data.

### Basics

The data consists heartrate readings of a child over 16 sessions of play therapy. Heartrate readings were taken at regular intervals from a wearable device on the child's wrist, creating between 1716 and 1832 reading for each session. 

### Cleaning

The heartrate monitor was on the child before the therapy session had started, and was removed at the end of the session. We are currently unsure of the exact lengths of the sessions (maybe we can get this from the tapes), so we're not really sure where the data begins in relation to the sessions. We do know where the session ends, so the final reading in each session could be considered a standardizing time, and we can shift all the na's to the front to account for our confusion there. We could also possibly remove the first values of all sessions to the length of the shortest session, which would standardize our reading counts while only throwing out less than ~6% of our longest session. 

In the end, I kind of like the idea of a transactional format (kind of, right? kind of tansactional), with session on x1, time on x2, and hr on x3. I believe we have extra bio data that we could then add as columns if we wanted to do some more general "excitement" measure. 


```{r, include=FALSE}
#install.packages("tidyverse")
library(tidyverse)
library(readxl)

raw <- read_xlsx('Play Therapy Wristband Data New V2.xlsx')[1:16]
```


```{r}
summary(raw)
```

Missing values:
```{r}
raw %>% 
  summarize(
    across(
      everything(), ~ sum(is.na(.))
    )
  ) %>%  t()
```

This just truncs them all to 1716 readings. Maybe we could go to the tapes and try and get a more accurate idea of where we should start, and maybe get the full data to come up with a better system.

```{r}
remove_na <- function(x){
  na_removed <- x[!is.na(x)]
  standardized <- na_removed %>% tail(1716)
  return(standardized)
}

df <- raw %>%
  lapply(remove_na) %>% 
  bind_cols()

df <- df %>% rowid_to_column("Time")

df
```
Altering the format for easy visualization.
```{r}
tdf <- df %>% 
  pivot_longer(2:17, names_to = "Session",values_to = "HR")

# add preceding 0 for ordering
tdf$Session <- tdf$Session %>% 
  str_replace_all("\\s(?=\\d$)"," 0")

tdf <- tdf %>% 
  arrange(Session)

tdf
```
I plan on adding in the other datasets, but hey all have slightly different numbers of readings. Maybe if we joined the three sheets into a single "session #" table, then did the remove_na function from before.

I wonder what the raw data looks like?

```{r}
raw_eda <- read_xlsx('Play Therapy Wristband Data New V2.xlsx', sheet=2)[1:16]
raw_temp <- read_xlsx('Play Therapy Wristband Data New V2.xlsx', sheet=3)[1:16]

raw_eda %>% 
  summarize(
    across(
      everything(), ~ sum(!is.na(.))
    )
  ) %>%  t()

raw_temp %>% 
  summarize(
    across(
      everything(), ~ sum(!is.na(.))
    )
  ) %>%  t()
```


Saving datasets out for reuse in other scripts.
```{r}
df %>% write_csv("df.csv")
tdf %>% write_csv("tdf.csv")
```


Did I make a mistake somewhere? Session 2 and 3 are identical in their last 500 readings, feom about 1250 on
```{r}
df %>% 
  select(Time, `Session 2`, `Session 3`) %>% 
  filter(Time > 1500 & Time < 1550)
```


```{r}

tdf %>%
  filter(Session == "Session 02") %>% 
  filter(Time > 1500 & Time < 1550)

tdf %>%
  filter(Session == "Session 03") %>% 
  filter(Time > 1500 & Time < 1550)
```

Ok, so it's here, is it in the Raw? The time will be a little off.

```{r}
x <- raw["Session 2"] %>% 
  na.omit() %>% 
  tail(10)
y <- raw["Session 3"] %>% 
  na.omit() %>% 
  tail(10)

cbind(x,y)

```

The raw data is borked on Session 2 and 3. They are the same for the last few hundred rows. 


